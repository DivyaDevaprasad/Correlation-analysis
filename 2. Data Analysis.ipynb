{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from numpy.random import randn\n",
    "from numpy.random import seed\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "import re                      # tool to perform pattern matching, used for data cleaning\n",
    "from textblob import TextBlob  # Sentiment Analysis tool\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_norm_stock(comp):\n",
    "    \n",
    "    # Read the stock data downloaded from Yahoo Finance.\n",
    "    stock_df = pd.read_csv(str(comp)+\".csv\")\n",
    "    stock_df.head()\n",
    "\n",
    "    # Stock data pre-processing\n",
    "    stock_df[\"Indicator(%)\"] = (stock_df[\"Close\"] - stock_df[\"Open\"]) * 100 / stock_df[\"Open\"]\n",
    "    stock_df[\"Label\"] = stock_df[\"Indicator(%)\"].apply(lambda x: 1 if x > 0 else 0)\n",
    "    stock_df.drop(columns= [\"High\",\"Low\",\"Adj Close\",\"Volume\"], axis = 0).head(20)\n",
    "\n",
    "    # Stock Data Analysis\n",
    "    cleaned_stock_df = stock_df[[\"Date\",\"Indicator(%)\"]]\n",
    "    cleaned_stock_df = cleaned_stock_df.set_index(\"Date\")\n",
    "    norm_STOCK_df=(cleaned_stock_df-cleaned_stock_df.mean())/cleaned_stock_df.std()\n",
    "    \n",
    "    # Save the stock analysis as csv\n",
    "    norm_STOCK_df.to_csv(comp+\"_STOCK.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_norm_senti(comp):\n",
    "    \n",
    "    # Read the data scraped\n",
    "    df = pd.read_csv(comp+\"_tweets.csv\")\n",
    "\n",
    "    col = [\"date\",\"tweet\",\"username\"]\n",
    "    newdf = df[col]\n",
    "    newdf['date'] = newdf['date'].apply(lambda x : x[:10])\n",
    "    newdf.set_index(\"date\", inplace =  True)\n",
    "    \n",
    "    # Twitter data pre-processing\n",
    "    symbol = comp\n",
    "    clean = newdf[\"tweet\"].str.lower()\n",
    "    clean = clean.apply(lambda x :re.sub('@[a-z]*','',x))      # Remove tags\n",
    "    clean = clean.apply(lambda x :re.sub('#[a-z0-9]*','',x))   # Remove hash tags\n",
    "    clean = clean.apply(lambda x :re.sub('[0-9]+[a-z]*',' ',x)) # Remove numnbers and associated text. Like : 1st, 2nd, nth....\n",
    "    clean = clean.apply(lambda x :re.sub('\\n','',x))            # Remove \\n\\t\n",
    "    clean = clean.apply(lambda x :re.sub('https?:\\/\\/.*',' ',x))        # Remove URLs\n",
    "    clean = clean.apply(lambda x :re.sub('[:;!-.,()%/?|]',' ',x))       # Remove Special characters\n",
    "    clean = clean.apply(lambda x :re.sub('$[a-z]*',' ',x))                        # Remove tickers and strings have $abc pattern\n",
    "    clean = clean.apply(lambda x : x.encode('ascii', 'ignore').decode('ascii'))   # Remove emojis\n",
    "    clean = clean.apply(lambda x :re.sub('[0-9]{4}-[0-9]{2}-[0-9]{2}','',x))      # Remove date\n",
    "    clean = clean.apply(lambda x :re.sub('[0-9]*','',x))\n",
    "\n",
    "    newdf[\"tweet\"] = clean\n",
    "    newdf = newdf.drop(\"username\", axis = 1)\n",
    "\n",
    "    # Twitter data Sentiment Analysis\n",
    "    testimonial = TextBlob(clean[50])\n",
    "    testimonial.sentiment\n",
    "\n",
    "    newdf[\"senti_polarity\"] = newdf[\"tweet\"].apply(lambda x: TextBlob(x).sentiment.polarity)\n",
    "    newdf[\"senti_subjectivity\"] = newdf[\"tweet\"].apply(lambda x: TextBlob(x).sentiment.subjectivity)\n",
    "\n",
    "#      # Save the Sentiment analysis as csv\n",
    "    twitter_df = newdf.groupby(\"date\").mean()\n",
    "    twitter_df.to_csv(comp+\"_SA_results.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Divya\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "C:\\Users\\Divya\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "companies = {'WMT','XOM','BRK', 'AMZN', 'AAPL'}\n",
    "\n",
    "for comp in companies:\n",
    "    ''' \n",
    "        For each company perform \n",
    "        Sentiment Analysis and Stock Analysis\n",
    "    '''\n",
    "    get_norm_senti(comp)\n",
    "    get_norm_stock(comp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
